{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imported Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cleaning Worktools**\n",
    "\n",
    "This section handles all the preparation methods for dealing with missing values and any unreliable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(dataframe, columns_to_drop):\n",
    "    \"\"\"\n",
    "    Drop one or multiple columns from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe: The input DataFrame.\n",
    "        columns_to_drop (str or list of str): The column name(s) to drop.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the specified columns dropped.\n",
    "    \"\"\"\n",
    "    if isinstance(columns_to_drop, str):\n",
    "        columns_to_drop = [columns_to_drop]\n",
    "\n",
    "    return dataframe.drop(columns=columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works on dropping the whole column(s) from the dataframe. It's going to be used once we encounter one or multiple fields that are fully null or most of the rows are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_rows(dataframe, subset):\n",
    "    \"\"\"\n",
    "    Drop rows that contain NaN/NaT or all blank values (spaces) in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe: The input DataFrame.\n",
    "        subset (list of str): The column names to consider when dropping rows.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing NaN or NaT values dropped.\n",
    "    \"\"\"\n",
    "    # Drop rows with any NaN or NaT values\n",
    "    dataframe = dataframe.dropna(subset=subset)\n",
    "\n",
    "    # Drop rows where all values are blank spaces\n",
    "    condition = dataframe.apply(lambda row: row.str.strip().eq('')).all(axis=1)\n",
    "    dataframe = dataframe[~condition]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method serves to removing just a number of rows within a subset of fields that contains null values (NaN, NaT) or blank values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(dataframe):\n",
    "    \"\"\"\n",
    "    Replace missing values in a DataFrame with appropriate fill values based on data type.\n",
    "    \n",
    "    For numerical columns, the missing values will be filled with the median.\n",
    "    For categorical columns, the missing values will be filled with the most frequent value.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe: The input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        The DataFrame with missing values replaced.\n",
    "    \"\"\"\n",
    "    # Replace blank spaces with NaN\n",
    "    dataframe = dataframe.replace('', np.nan)\n",
    "    \n",
    "    # Fill missing values in numerical columns with the median\n",
    "    numeric_columns = dataframe.select_dtypes(include=[np.number])\n",
    "    dataframe[numeric_columns.columns] = dataframe[numeric_columns.columns].fillna(numeric_columns.median())\n",
    "    \n",
    "    # Fill missing values in categorical columns with the most frequent value\n",
    "    categorical_columns = dataframe.select_dtypes(include=['object'])\n",
    "    dataframe[categorical_columns.columns] = dataframe[categorical_columns.columns].fillna(categorical_columns.mode().iloc[0])\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is being defined to replace missing values in a DataFrame with appropriate fill values based on data type. As a choice, we are tending to replace the numerical columns with the median and the categorical columns with the most frequent values (the mode, statistically speaking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_if_negative_diff(dataframe, dt1, dt2):\n",
    "    \"\"\"\n",
    "    Switches the values of datetime1 (dt1) and datetime2 (dt2) in the dataframe\n",
    "    if datetime1 is greater than datetime2.\n",
    "\n",
    "    Args:\n",
    "        dataframe: the dataframe containing 'datetime1' and 'datetime2' columns.\n",
    "        dt1 (str): the field's name representing the first datetime\n",
    "        dt2 (str): the field's name representing the second datetime\n",
    "\n",
    "    Returns:\n",
    "        The permuted dataframe with switched datetime values if applicable.\n",
    "    \"\"\"\n",
    "    datetime1 = dataframe[dt1]\n",
    "    datetime2 = dataframe[dt2]\n",
    "    if datetime1 > datetime2:\n",
    "        dataframe[dt1], dataframe[dt2] = datetime2, datetime1\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of this method is toggling between 2 datetimes that have negative differential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_datetime_nulls(dataframe, column_name):\n",
    "    \"\"\"\n",
    "    Replace null datetime values in a DataFrame column using time-based interpolation.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe: The DataFrame containing the column with null datetime values.\n",
    "        column_name (str): The name of the column with datetime values to interpolate.\n",
    "\n",
    "    Returns:\n",
    "        The DataFrame with null datetime values replaced by interpolated values.\n",
    "    \"\"\"\n",
    "    # Convert the specified column to datetime dtype\n",
    "    dataframe[column_name] = pd.to_datetime(dataframe[column_name])\n",
    "\n",
    "    # Perform interpolation for missing values using 'bfill' method\n",
    "    dataframe[column_name] = dataframe[column_name].fillna(method='bfill')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a DataFrame and the name of the column with datetime values that need interpolation. Interpolation is a mathematical method that estimates the missing values based on the known values surrounding them.\n",
    "\n",
    "Pandas provides the `interpolate()` method, which can be used to perform linear or time-based interpolation on datetime columns.\n",
    "\n",
    "The resulting DataFrame will have the null datetime values replaced with interpolated values based on the surrounding known values and the time differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_nan_columns(dataframe, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Fetches the null columns and Separates the most nullified columns for the others.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe: The DataFrame containing the column with null values.\n",
    "        threshold (float): A metric with which we separate the dataframe \n",
    "                           based upon holding missing values.\n",
    "\n",
    "    Returns:\n",
    "        Two lists of columns names.\n",
    "    \"\"\"\n",
    "    # Store the number of null values within a dataframe df\n",
    "    df = pd.DataFrame(dataframe.isna().sum(), columns=['Nb_null'])\n",
    "\n",
    "    # Separate the number of nuls that surpass the length of the dataframe\n",
    "    cols_to_drop = df[df['Nb_null'] > detb_data.shape[0] * threshold]\n",
    "\n",
    "    # Separate the number of nuls that are less than the length of the dataframe except 0\n",
    "    cols_to_manipulate_nan = df[(df['Nb_null'] <= detb_data.shape[0] * threshold) & (df['Nb_null'] > 0)]\n",
    "\n",
    "    # Return just the name of columns\n",
    "    return cols_to_drop.index, cols_to_manipulate_nan.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method stands out as a way of retrieving the columns that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values_subset(dataframe, subset_columns):\n",
    "    \"\"\"\n",
    "    Replace missing values in a subset of columns of a DataFrame with appropriate fill values based on data type.\n",
    "\n",
    "    For numerical columns, the missing values will be filled with the median.\n",
    "    For categorical columns, the missing values will be filled with the most frequent value.\n",
    "\n",
    "    Args:\n",
    "        dataframe: The input DataFrame.\n",
    "        subset_columns: List of column names to fill missing values in.\n",
    "\n",
    "    Returns:\n",
    "        The DataFrame with missing values replaced for the specified subset of columns.\n",
    "    \"\"\"\n",
    "    # Fill missing values in numerical columns of the subset with the median\n",
    "    numeric_columns = dataframe[subset_columns].select_dtypes(include=[np.number])\n",
    "    dataframe[numeric_columns.columns] = dataframe[numeric_columns.columns].fillna(numeric_columns.median())\n",
    "\n",
    "    # Fill missing values in categorical columns of the subset with the most frequent value\n",
    "    categorical_columns = dataframe[subset_columns].select_dtypes(include=['object'])\n",
    "    dataframe[categorical_columns.columns] = dataframe[categorical_columns.columns].fillna(categorical_columns.mode().iloc[0])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method replaces missing values in a subset of columns of a DataFrame with appropriate fill values based on data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def replace_nan_with_knn_classifier(dataframe, target_column, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Replace NaN values in the target column of the DataFrame using k-Nearest Neighbors (k-NN) classification for prediction.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The input DataFrame.\n",
    "        target_column (str): The name of the column containing NaN values to be predicted. Default is 'LOGIN_USER'.\n",
    "        n_neighbors (int): The number of neighbors to consider for k-NN classification. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with NaN values in the specified column replaced with predicted values.\n",
    "    \"\"\"\n",
    "    # Make a copy of the original DataFrame\n",
    "    df_copy = dataframe.copy()\n",
    "\n",
    "    # Store the data types of datetime columns for conversion back after label encoding\n",
    "    datetime_columns = df_copy.select_dtypes(include='datetime64').columns\n",
    "\n",
    "    # Drop datetime columns temporarily\n",
    "    df_copy.drop(columns=datetime_columns, inplace=True)\n",
    "\n",
    "    # Label encode all the categorical columns\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in df_copy.select_dtypes(include='object'):\n",
    "        df_copy[col] = label_encoder.fit_transform(df_copy[col].astype(str))\n",
    "\n",
    "    # Separate the DataFrame into null and non-null values in the target column\n",
    "    df_not_null = df_copy.dropna(subset=[target_column])\n",
    "    df_null = df_copy[df_copy[target_column].isnull()]\n",
    "\n",
    "    # Check if there are non-null values in the target column\n",
    "    if len(df_not_null) == 0:\n",
    "        raise ValueError(\"No non-null values found in the target column.\")\n",
    "\n",
    "    # Features and target for non-null values\n",
    "    features_not_null = df_not_null.drop(target_column, axis=1)\n",
    "    target_not_null = df_not_null[target_column]\n",
    "\n",
    "    # Fit the non-null values to the k-NN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_classifier.fit(features_not_null, target_not_null)\n",
    "\n",
    "    # Reorder columns in df_null to match the order of features_not_null\n",
    "    df_null_reordered = df_null[features_not_null.columns]\n",
    "    print(df_null.head())\n",
    "    print(len(df_null) > 0)\n",
    "    # Check if there are any null values to predict\n",
    "    if len(df_null) > 0:\n",
    "        # Predict the null values in the target column\n",
    "        predicted_labels = knn_classifier.predict(df_null_reordered)\n",
    "\n",
    "        # Convert the predicted labels back to original categorical values using the original label encoder\n",
    "        predicted_values = label_encoder.inverse_transform(predicted_labels)\n",
    "        print(predicted_values)\n",
    "        # Replace NaN values in the target column with predicted values\n",
    "        df_copy.loc[df_copy[target_column].isnull(), target_column] = predicted_values\n",
    "\n",
    "    # Convert the target column back to the original labels\n",
    "    for col in df_copy.select_dtypes(include='object'):\n",
    "        df_copy[col] = label_encoder.inverse_transform(df_copy[col])\n",
    "\n",
    "    # Restore the datetime columns\n",
    "    for col in datetime_columns:\n",
    "        df_copy[col] = dataframe[col]\n",
    "\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works on replacing NaN values in a specific column of the DataFrame using k-Nearest Neighbors (k-NN) imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_label_encoded_values(df_encoded, df_categorical, target_column):\n",
    "    \"\"\"\n",
    "    Replace label encoded values in the DataFrame 'df_encoded' with the corresponding categorical values from 'df_categorical'.\n",
    "\n",
    "    Parameters:\n",
    "        df_encoded (pd.DataFrame): The DataFrame containing label encoded values to be replaced.\n",
    "        df_categorical (pd.DataFrame): The DataFrame containing the corresponding categorical values.\n",
    "        target_column (str): The name of the target column to replace the values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame 'df_encoded' with the label encoded values replaced by the categorical values.\n",
    "    \"\"\"\n",
    "    # Create a mapping dictionary to store label encoded values and their corresponding alphabetical values\n",
    "    mapping = {}\n",
    "\n",
    "    # Iterate over the target column in both DataFrames simultaneously\n",
    "    for encoded_val, categorical_val in zip(df_encoded[target_column], df_categorical[target_column]):\n",
    "        if not pd.isna(encoded_val) and not pd.isna(categorical_val):\n",
    "            # Store the mapping of label encoded value to the corresponding alphabetical value\n",
    "            mapping[encoded_val] = categorical_val\n",
    "\n",
    "    # Replace label encoded values with their corresponding categorical values\n",
    "    df_encoded[target_column] = df_encoded[target_column].replace(mapping)\n",
    "\n",
    "    return df_encoded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
